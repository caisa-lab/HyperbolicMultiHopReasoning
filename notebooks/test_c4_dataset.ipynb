{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from src.util import load_c4_dataset\n",
    "from src.datasets import C4Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '../c4/en/c4-train.{:05d}-of-01024.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Dataframe with c4 Data...: 100%|██████████| 5/5 [00:41<00:00,  8.31s/it]\n"
     ]
    }
   ],
   "source": [
    "list_of_texts = load_c4_dataset(base_path, 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "model_name = \"google/t5-v1_1-base\"\n",
    "print(\"Loading Tokenizer...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleanup Dataset: Remove texts with < 3 corrupted tokens: 100%|██████████| 1781586/1781586 [00:27<00:00, 63663.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned 17181 Datapoints remaining 1764405 Datapoints\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "c4_dataset = C4Dataset(list_of_texts, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "c4_dataloader_train = DataLoader(c4_dataset, batch_size = 32, shuffle=True)\n",
    "c4_iter = iter(c4_dataloader_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_batch = next(c4_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "input, target = first_batch[0], first_batch[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_inputs = tokenizer(input, padding=True, truncation=True, return_tensors='pt')\n",
    "tokenized_labels = tokenizer(target, padding=True, truncation=True, return_tensors='pt')\n",
    "input_ids = tokenized_inputs['input_ids']\n",
    "attention_mask = tokenized_inputs['attention_mask']\n",
    "labels = tokenized_labels['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([   71,     3,    75,  2256,    29,    19,  2681,  1084,    42,   590,\n",
      "            3,     9, 10433,    12,    36,   261,    12,  1520,    12,    52,\n",
      "         2951,    12,  3240, 10911,    11,    92,     3, 25948,    12,  3946,\n",
      "            3,     9,  5032,    42,  2071,    24,   133,  2904,    36,  1256,\n",
      "           12,  2862,     5,    37, 18712,    13,     8,  1128,    13,     8,\n",
      "          496,   271,   885,    12,     8,   387,    11,     8,   194,  2061,\n",
      "          991,   502,    30,     3, 25149, 13704,    33,   321,  2081,  1187,\n",
      "          175,  2807,     5,  1698,     3, 12851,     3, 15550,    16,   812,\n",
      "           11,   150,   192,    33,  1776,  9391,     3,   104,    66,  6978,\n",
      "           13,     8,   481,     6,   871,    11,  2692,    13,     8,   496,\n",
      "            5,    27,  1800,    34,    47,   359,    12,  4277, 17951,     6,\n",
      "         2807,    11, 28358,  2479,    12,     8,   481,    12, 17101,    29,\n",
      "           70, 13645,    12,     8,   775,  2790,    13,    70,  1164,     6,\n",
      "          892,    11,  1543,     5,    37,  7300,     7,    33,    46,   359,\n",
      "           11,  9240,  2736,     5,   282,    80,  6914,   590,     8,   628,\n",
      "            8,  7300,     7,  2385,    16,     3,     9,   861, 32099,    13,\n",
      "         9087,    11,  5484,    25,    16,    21,     3,     9, 28358,   351,\n",
      "            5,   506,     3,  4267,  3757,  9434,  7300,     7,   130,   261,\n",
      "           38,     3,     9,   542,  1391,    57,     8, 19771,   151, 32098,\n",
      "            3,     6,     8, 18266,    29,   173,    49,  2837,   687,   151,\n",
      "            5,    37,  3648,   256,  7260,     7,    33,    13,  4262,  2677,\n",
      "        32097,   328,   560,  4262, 15665,     6,   388,  8377,    11, 32096,\n",
      "            3,     7,  4759,    16,  3625,   264,    60,   195,     5,   432,\n",
      "          158,  7310,     7,    43,   118,     3, 15551,    11,  4759, 32095,\n",
      "            3,     6,   451,   291,  3552,    11,     8,  3825,   616,     5,\n",
      "        32094,  5470,  1432,    95,    30, 32093,     3,     5, 32092,     3,\n",
      "           10, 32091, 32090,     3,   195, 14542,  1121, 32089, 28020,     5,\n",
      "         1562,  4188,    12, 32088,    41,  7855,    29, 32087,   491, 32086,\n",
      "            3,   729,    41,  7754,     7, 28020,    61,    11, 32085,     3,\n",
      "         3877,     9, 16179,   137,     1,     1,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n"
     ]
    }
   ],
   "source": [
    "print(input_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master_thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
