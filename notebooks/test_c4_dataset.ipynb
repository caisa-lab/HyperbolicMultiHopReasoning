{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Simon\\anaconda3\\envs\\master_thesis\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from src.util import load_c4_dataset\n",
    "from src.datasets import C4Dataset\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '../dataset/c4/en/c4-train.{:05d}-of-01024.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Dataframe with c4 Data...: 100%|██████████| 1/1 [00:08<00:00,  8.94s/it]\n"
     ]
    }
   ],
   "source": [
    "list_of_texts = load_c4_dataset(base_path, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "model_name = \"google/t5-v1_1-base\"\n",
    "print(\"Loading Tokenizer...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "c4_dataset = C4Dataset(list_of_texts, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Total tokens: 440\n",
      "66\n",
      " Span Lengths: [5 4 4 2 2 3 5 1 2 5 8 1 1 5 1 1 2 2 2 3 3 4]\n",
      "Span Starts: [191, 279, 299, 306, 311, 338, 346, 356, 357, 362, 367, 386, 391, 394, 403, 405, 406, 409, 412, 417, 421, 427]\n",
      "Length of Target IDs: 88\n",
      "Input Sequence: Discussion in 'Mac OS X Lion (10.7)' started by axboi87, Jan 20, 2012. I've got a 500gb internal drive and a 240gb SSD. When trying to restore using disk utility i'm given the error \"Not enough space on disk ____ to restore\" But I shouldn't have to do that!!! Any ideas or workarounds before resorting to the above? Use Carbon Copy Cloner to copy one drive to the other. I've done this several times going from larger HDD to smaller SSD and I wound up with a bootable SSD drive. One step you have to remember not to skip is to use Disk Utility to partition the SSD as GUID partition scheme HFS+ before doing the clone. If it came Apple Partition Scheme, even if you let CCC do the clo<extra_id_0>resulting drive won't be bootable. CCC usually works in \"file mode\" and it can easily copy a larger drive (that's mostly empty) onto a smaller drive. If you tell CCC to clone a drive you did NOT boot from, it can work in block copy mode where the destination drive must be the same size or larger than the drive you are <extra_id_1> (if I recall). I've actually done this somehow on Disk Utility<extra_id_2>ing from <extra_id_3> drive (or<extra_id_4> dvd) so not running disk utility from the drive your cloning) and had it work just fine from larger to<extra_id_5> clone.<extra_id_6> cloning to<extra_id_7><extra_id_8> bootable Apple<extra_id_9><extra_id_10> using DU to go larger to smaller was when I<extra_id_11> trying to make <extra_id_12> Lion install<extra_id_13>unable to restore Install<extra_id_14>D<extra_id_15><extra_id_16>g<extra_id_17>a<extra_id_18>GB USB stick<extra_id_19> the<extra_id_20>'t fit<extra_id_21> more than 4 GB of data.</s>\n",
      "Target Sequence: <extra_id_0>ne, the <extra_id_1>cloning from<extra_id_2> several times (boot<extra_id_3>a different<extra_id_4> even the<extra_id_5> smaller bootable<extra_id_6> Definitely format the drive<extra_id_7> first<extra_id_8>, as<extra_id_9> etc.. Thanks for<extra_id_10> pointing this out. My only experience<extra_id_11> was<extra_id_12>a<extra_id_13> stick and I was <extra_id_14>ES<extra_id_15>.<extra_id_16>dm<extra_id_17> to <extra_id_18> 4 <extra_id_19> but of course<extra_id_20> reason that wouldn<extra_id_21> is there was slightly\n"
     ]
    }
   ],
   "source": [
    "input, target = c4_dataset[1]\n",
    "print(f\"Input Sequence: {input}\")\n",
    "print(f\"Target Sequence: {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master_thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
