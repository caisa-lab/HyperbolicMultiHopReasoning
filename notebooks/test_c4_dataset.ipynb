{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Simon\\anaconda3\\envs\\master_thesis\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from src.util import load_c4_dataset\n",
    "from src.datasets import C4Dataset\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '../dataset/c4/en/c4-train.{:05d}-of-01024.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Dataframe with c4 Data...: 100%|██████████| 1/1 [00:08<00:00,  8.95s/it]\n"
     ]
    }
   ],
   "source": [
    "list_of_texts = load_c4_dataset(base_path, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "model_name = \"google/t5-v1_1-base\"\n",
    "print(\"Loading Tokenizer...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "c4_dataset = C4Dataset(list_of_texts, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Total tokens: 440\n",
      "66\n",
      " Span Lengths: [4 3 3 4 4 4 4 1 3 4 1 1 1 3 5 4 3 2 2 5 1 4]\n",
      "Span Starts: [267, 278, 314, 317, 334, 339, 344, 356, 358, 366, 370, 378, 379, 382, 385, 397, 406, 409, 413, 417, 426, 429]\n",
      "Length of Target IDs: 88\n",
      "Length of Input ids: 396\n",
      "Input Sequence: Discussion in 'Mac OS X Lion (10.7)' started by axboi87, Jan 20, 2012. I've got a 500gb internal drive and a 240gb SSD. When trying to restore using disk utility i'm given the error \"Not enough space on disk ____ to restore\" But I shouldn't have to do that!!! Any ideas or workarounds before resorting to the above? Use Carbon Copy Cloner to copy one drive to the other. I've done this several times going from larger HDD to smaller SSD and I wound up with a bootable SSD drive. One step you have to remember not to skip is to use Disk Utility to partition the SSD as GUID partition scheme HFS+ before doing the clone. If it came Apple Partition Scheme, even if you let CCC do the clone, the resulting drive won't be bootable. CCC usually works in \"file mode\" and it can easily copy a larger drive (that's mostly empty) onto a smaller drive. If you tell CCC to clone a drive you did NOT boot from, it can work in block copy mode where the destination drive must<extra_id_0> or larger than the drive you are<extra_id_1>ing from (if I recall). I've actually done this somehow on Disk Utility several times (booting from a different drive (or even the dvd<extra_id_2><extra_id_3> the drive your cloning) and had it work just<extra_id_4> smaller<extra_id_5>n<extra_id_6> format the drive cloning to<extra_id_7>,<extra_id_8> Apple etc.. Thanks<extra_id_9><extra_id_10>. My only experience using DU<extra_id_11><extra_id_12> larger to<extra_id_13><extra_id_14> a Lion install stick and I<extra_id_15> restore InstallESD.<extra_id_16><extra_id_17>a 4<extra_id_18> USB stick<extra_id_19> that wouldn't<extra_id_20> is there<extra_id_21> 4 GB of data.</s>\n",
      "Target Sequence: <extra_id_0> be the same size<extra_id_1> clon<extra_id_2>) so not<extra_id_3> running disk utility from<extra_id_4> fine from larger to<extra_id_5> bootable clo<extra_id_6>e. Definitely<extra_id_7> first<extra_id_8> as bootable<extra_id_9> for pointing this<extra_id_10> out<extra_id_11> to<extra_id_12> go<extra_id_13> smaller was when<extra_id_14> I was trying to make<extra_id_15> was unable to<extra_id_16>dmg<extra_id_17> to <extra_id_18> GB<extra_id_19> but of course the reason<extra_id_20> fit<extra_id_21> was slightly more than\n"
     ]
    }
   ],
   "source": [
    "input, target = c4_dataset[1]\n",
    "print(f\"Input Sequence: {input}\")\n",
    "print(f\"Target Sequence: {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master_thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
